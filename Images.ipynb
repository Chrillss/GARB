{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.2583 - acc: 0.9240\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1047 - acc: 0.9672\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0721 - acc: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ca06ba3c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist # dataset: 28x28 bilder av handskrivna siffror 0-9\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() #Lägger in siffrorna i träning och test variablar\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "model = tf.keras.models.Sequential() #\"feedforward model\" ett linjärt nätverk\n",
    "model.add(tf.keras.layers.Flatten()) #input-lager\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) #hidden layer, 128 neuroner. Aktivationsfunktion = relu\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) #ett till av ett likadant gömda-lager \n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax)) #10 output-neuroner för 10 svar (0-9) \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy']) #adam som optimizer scc som loss-funktion\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/step\n",
      "0.08699274508273229 0.9738\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test) #Man ska hoppas på att modellen generaliserar hur olika siffror ser ut och inte momorizerar din specifika data.\n",
    "print(val_loss, val_acc) #testar för overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #gör så jag kan se bilderna \n",
    " \n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict([x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4505467e-09 1.5952155e-08 4.2525679e-07 ... 9.9988234e-01\n",
      "  1.2114825e-09 5.1810339e-08]\n",
      " [2.1883784e-12 1.3089052e-05 9.9998474e-01 ... 5.4933985e-10\n",
      "  5.6162914e-08 2.7213518e-12]\n",
      " [2.1599545e-08 9.9974376e-01 1.9772255e-05 ... 1.3824964e-04\n",
      "  4.5355544e-05 4.0634697e-07]\n",
      " ...\n",
      " [2.9719138e-09 3.0847337e-07 2.5344167e-09 ... 5.8416863e-06\n",
      "  1.5135088e-06 1.0950634e-05]\n",
      " [5.6035647e-06 1.8064202e-07 7.7789881e-09 ... 7.8182460e-08\n",
      "  8.2374600e-06 2.5376174e-08]\n",
      " [1.5432497e-06 4.9234143e-07 7.6699689e-06 ... 2.3701906e-08\n",
      "  2.0498699e-06 6.4288152e-08]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[2])\n",
    "plt.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
